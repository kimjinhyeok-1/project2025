
<template>
  <div>
    <h2>ğŸ¤ í”„ë¡ íŠ¸ VAD + MediaRecorder (VADì— streamë§Œ ì „ë‹¬)</h2>
    <button @click="startRecording" :disabled="isRecording">ë…¹ìŒ ì‹œì‘</button>
    <button @click="stopRecording" :disabled="!isRecording">ë…¹ìŒ ì¢…ë£Œ</button>
    <p v-if="question">ğŸ§  AI ì§ˆë¬¸: {{ question }}</p>
  </div>
</template>

<script>
import { ref, onBeforeUnmount } from 'vue'
import vad from 'voice-activity-detection'

const BASE_URL = 'https://project2025-backend.onrender.com/vad/upload_audio_chunk'

export default {
  setup() {
    const isRecording = ref(false)
    const question = ref('')
    let audioContext = null
    let mediaStream = null
    let mediaRecorder = null
    let audioChunks = []
    let vadController = null

    const sendAudio = (blob) => {
      const formData = new FormData()
      formData.append('file', blob, 'chunk.webm')

      fetch(BASE_URL, {
        method: 'POST',
        body: formData,
        credentials: 'include',
      })
        .then(res => res.json())
        .then(data => {
          console.log("ğŸ“¥ ì‘ë‹µ:", data)
          question.value = data.question || 'â” ì§ˆë¬¸ ì—†ìŒ'
        })
        .catch(err => console.error('âŒ ì „ì†¡ ì‹¤íŒ¨:', err))
    }

    const setupVAD = (audioContext, stream) => {
      vadController = vad(audioContext, stream, {
        onVoiceStart: () => {
          console.log('ğŸ™ï¸ ìŒì„± ì‹œì‘')
          if (mediaRecorder && mediaRecorder.state === 'inactive') {
            audioChunks = []
            mediaRecorder.start()
            console.log('â–¶ï¸ MediaRecorder ì‹œì‘')
          }
        },
        onVoiceStop: () => {
          console.log('ğŸ”‡ ìŒì„± ì¢…ë£Œ')
          if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop()
            console.log('â¹ï¸ MediaRecorder ì •ì§€')
          }
        },
        interval: 300,
        voice_stop: 800,
      })
    }

    const startRecording = async () => {
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true })
        console.log("âœ… mediaStream íƒ€ì… í™•ì¸:", mediaStream && mediaStream.constructor.name)

        await new Promise((resolve) => setTimeout(resolve, 200)) // ì•ˆì •í™” ëŒ€ê¸°

        audioContext = new AudioContext()

        // âœ… streamë§Œ ë„˜ê¹€
        setupVAD(audioContext, mediaStream)

        // MediaRecorder ì„¸íŒ…
        mediaRecorder = new MediaRecorder(mediaStream)
        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            audioChunks.push(e.data)
          }
        }

        mediaRecorder.onstop = () => {
          const blob = new Blob(audioChunks, { type: 'audio/webm' })
          sendAudio(blob)
        }

        isRecording.value = true
      } catch (err) {
        console.error('ğŸ¤ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', err)
      }
    }

    const stopRecording = () => {
      if (vadController && vadController.stop) vadController.stop()
      if (mediaRecorder && mediaRecorder.state === 'recording') mediaRecorder.stop()
      if (mediaStream) mediaStream.getTracks().forEach(track => track.stop())
      if (audioContext) audioContext.close()
      isRecording.value = false
    }

    onBeforeUnmount(() => {
      stopRecording()
    })

    return {
      startRecording,
      stopRecording,
      isRecording,
      question,
    }
  }
}
</script>
