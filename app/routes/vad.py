# ========================
# ğŸ“¦ Backend: FastAPI ì½”ë“œ (likes ë°˜ì˜ íŒ¨ì¹˜ í¬í•¨)
# ========================

from fastapi import APIRouter, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional
from app.services.gpt import generate_expected_questions
from app.database import get_db_context
from app.models import GeneratedQuestion
from sqlalchemy import select
from datetime import datetime
import asyncio
import re

router = APIRouter()
text_buffer: list[str] = []

# ìš”ì²­ ëª¨ë¸
class TextChunkRequest(BaseModel):
    text: str

class LikeRequest(BaseModel):
    question_id: int

# ì§ˆë¬¸ ì„¸íŠ¸ ì¡°íšŒ
async def get_question_set(db, q_id: Optional[int] = None) -> Optional[GeneratedQuestion]:
    if q_id is not None:
        result = await db.execute(select(GeneratedQuestion).where(GeneratedQuestion.id == q_id))
    else:
        result = await db.execute(select(GeneratedQuestion).order_by(GeneratedQuestion.id.desc()).limit(1))
    return result.scalar_one_or_none()

# STT í…ìŠ¤íŠ¸ ëˆ„ì 
@router.post("/upload_text_chunk")
async def upload_text_chunk(body: TextChunkRequest):
    text = body.text.strip()
    if not text:
        raise HTTPException(400, detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    text_buffer.append(text)
    return {"message": "í…ìŠ¤íŠ¸ ëˆ„ì  ì™„ë£Œ", "buffer_length": len(text_buffer)}

# ì§ˆë¬¸ ìƒì„± íŠ¸ë¦¬ê±°
@router.post("/trigger_question_generation")
async def trigger_question_generation():
    if not text_buffer:
        raise HTTPException(400, detail="ëˆ„ì ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    full_text = " ".join(text_buffer)
    if not is_valid_paragraph(full_text):
        raise HTTPException(400, detail="ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    try:
        questions = await asyncio.to_thread(generate_expected_questions, full_text)
    except Exception as e:
        raise HTTPException(500, detail=f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

    if not questions:
        raise HTTPException(500, detail="ì§ˆë¬¸ ìƒì„±ì„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    obj = GeneratedQuestion(
        paragraph=full_text,
        questions=questions[:5],
        likes=[0] * min(5, len(questions)),
        created_at=datetime.utcnow()
    )
    async with get_db_context() as db:
        db.add(obj)
        await db.commit()
        await db.refresh(obj)

    text_buffer.clear()
    return {
        "message": "ì§ˆë¬¸ ìƒì„± ë° ì €ì¥ ì™„ë£Œ",
        "q_id": obj.id,
        "paragraph": obj.paragraph,
        "questions": obj.questions,
        "created_at": obj.created_at.isoformat()
    }

# ìµœì‹  q_id ë°˜í™˜
@router.get("/questions/latest_id")
async def get_latest_qid():
    async with get_db_context() as db:
        result = await db.execute(select(GeneratedQuestion.id).order_by(GeneratedQuestion.id.desc()).limit(1))
        q_id = result.scalar()
    return {"q_id": q_id}

# ìµœì‹  ì§ˆë¬¸ ì„¸íŠ¸ ë°˜í™˜
@router.get("/questions/latest")
async def get_latest_questions():
    async with get_db_context() as db:
        question_set = await get_question_set(db)

    if not question_set:
        raise HTTPException(404, detail="ì§ˆë¬¸ ì„¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    return {
        "q_id": question_set.id,
        "paragraph": question_set.paragraph,
        "questions": [
            {"text": q, "likes": question_set.likes[i]} for i, q in enumerate(question_set.questions)
        ],
        "created_at": question_set.created_at.isoformat()
    }

# ì¢‹ì•„ìš”
@router.patch("/question/{q_id}/like")
async def like_question(q_id: int, body: LikeRequest):
    async with get_db_context() as db:
        question_set = await get_question_set(db, q_id)

        if not question_set or not (0 <= body.question_id < len(question_set.likes)):
            raise HTTPException(404, detail="ì§ˆë¬¸ ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        updated_likes = question_set.likes.copy()
        updated_likes[body.question_id] += 1
        question_set.likes = updated_likes

        await db.commit()
        await db.refresh(question_set)

        print(f"[LIKE PATCH] q_id={q_id}, question_id={body.question_id}, likes={question_set.likes}")
        return {"message": "ì¢‹ì•„ìš” ë°˜ì˜ ì™„ë£Œ"}

# ì¢‹ì•„ìš” ì·¨ì†Œ
@router.patch("/question/{q_id}/unlike")
async def unlike_question(q_id: int, body: LikeRequest):
    async with get_db_context() as db:
        question_set = await get_question_set(db, q_id)

        if not question_set or not (0 <= body.question_id < len(question_set.likes)):
            raise HTTPException(404, detail="ì§ˆë¬¸ ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        updated_likes = question_set.likes.copy()
        if updated_likes[body.question_id] > 0:
            updated_likes[body.question_id] -= 1
            question_set.likes = updated_likes
            await db.commit()
            await db.refresh(question_set)
            print(f"[UNLIKE PATCH] q_id={q_id}, question_id={body.question_id}, likes={question_set.likes}")
            return {"message": "ì¢‹ì•„ìš” ì·¨ì†Œ ì™„ë£Œ"}
        else:
            return {"message": "ì´ë¯¸ 0ì…ë‹ˆë‹¤."}

# ì¢‹ì•„ìš” ìˆœìœ¼ë¡œ ì§ˆë¬¸ ì •ë ¬
@router.get("/questions/popular_likes")
async def get_popular_likes(q_id: Optional[int] = None):
    async with get_db_context() as db:
        question_set = await get_question_set(db, q_id)

    if not question_set:
        return {"results": []}

    questions_with_likes = [
        {"text": q, "likes": question_set.likes[i]} for i, q in enumerate(question_set.questions)
    ]
    sorted_questions = sorted(questions_with_likes, key=lambda x: x["likes"], reverse=True)

    print(f"[POPULAR GET] q_id={q_id}, sorted={sorted_questions}")

    return {"results": sorted_questions}

# ë¬¸ì¥ ìœ íš¨ì„± ì²´í¬
def split_text_into_sentences(text: str) -> list[str]:
    return [s.strip() for s in re.split(r"(?<=[.?!])\s+|\n", text) if s.strip()]

def is_valid_paragraph(text: str) -> bool:
    return len(split_text_into_sentences(text)) >= 2 or len(text.strip()) >= 20