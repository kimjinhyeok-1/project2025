import os
import asyncio
import openai
from fastapi import APIRouter, Request, HTTPException

router = APIRouter()

# ğŸ“Œ ì„œë²„ ë©”ëª¨ë¦¬ ê¸°ë°˜ ëˆ„ì  í…ìŠ¤íŠ¸ ì €ì¥ì†Œ
lecture_texts = {}  # {lecture_id: [chunk1, chunk2, ...]}

# ğŸ“Œ OpenAI Client ì„¤ì •
openai_client = openai.AsyncOpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)

# ğŸ“Œ Assistant ID (.envì— ì €ì¥ëœ ìš”ì•½ ì „ìš© Assistant)
ASSISTANT_ID = os.getenv("LECTURE_SUMMARY_ASSISTANT_ID")

# âœ‚ï¸ í…ìŠ¤íŠ¸ë¥¼ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜
def split_text(text: str, max_chars: int = 4000) -> list:
    blocks = []
    while len(text) > max_chars:
        idx = text[:max_chars].rfind('\n')  # ìµœëŒ€í•œ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        if idx == -1:
            idx = max_chars
        blocks.append(text[:idx].strip())
        text = text[idx:].strip()
    if text:
        blocks.append(text)
    return blocks

@router.post("/upload_text_chunk")
async def upload_text_chunk(request: Request):
    """í…ìŠ¤íŠ¸ chunkë¥¼ ë°›ì•„ì„œ lecture_idë³„ë¡œ ëˆ„ì  ì €ì¥"""
    body = await request.json()
    lecture_id = body.get("lecture_id")
    text_chunk = body.get("text", "").strip()

    if not lecture_id or not text_chunk:
        raise HTTPException(status_code=400, detail="lecture_idì™€ textëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")

    if lecture_id not in lecture_texts:
        lecture_texts[lecture_id] = []
    lecture_texts[lecture_id].append(text_chunk)

    return {"message": "Chunk ì €ì¥ ì™„ë£Œ"}

@router.get("/lecture_text/{lecture_id}")
async def get_lecture_text(lecture_id: str):
    """í˜„ì¬ê¹Œì§€ ì €ì¥ëœ ìˆ˜ì—… í…ìŠ¤íŠ¸ í™•ì¸"""
    if lecture_id not in lecture_texts:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ìˆ˜ì—…ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    return {
        "lecture_id": lecture_id,
        "texts": lecture_texts[lecture_id],
        "full_text": "\n".join(lecture_texts[lecture_id])
    }

@router.post("/reset_lecture/{lecture_id}")
async def reset_lecture(lecture_id: str):
    """íŠ¹ì • ìˆ˜ì—… í…ìŠ¤íŠ¸ ì´ˆê¸°í™”"""
    if lecture_id in lecture_texts:
        del lecture_texts[lecture_id]
    return {"message": f"{lecture_id} ìˆ˜ì—… ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ"}

@router.post("/summarize_lecture")
async def summarize_lecture(request: Request):
    """ìˆ˜ì—… ì¢…ë£Œ ì‹œ ì „ì²´ í…ìŠ¤íŠ¸ ìš”ì•½"""
    body = await request.json()
    lecture_id = body.get("lecture_id")

    if not lecture_id:
        raise HTTPException(status_code=400, detail="lecture_idê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    chunks = lecture_texts.get(lecture_id)
    if not chunks:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ìˆ˜ì—… í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 1. ì „ì²´ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
    full_text = "\n".join(chunks)

    # 2. AIë¥¼ ì´ìš©í•´ í…ìŠ¤íŠ¸ í´ë¦°ì—…
    print("ğŸ§¹ AI í´ë¦°ì—… ì‹œì‘...")
    cleaned_text = await ai_clean_text(full_text)

    # 3. í…ìŠ¤íŠ¸ ë¶„í• 
    text_blocks = split_text(cleaned_text, max_chars=4000)
    print(f"âœ… í´ë¦°ì—… í›„ í…ìŠ¤íŠ¸ ë¸”ë¡ ìˆ˜: {len(text_blocks)}ê°œ")

    # 4. ê° ë¸”ë¡ ìš”ì•½
    partial_summaries = []
    for idx, block in enumerate(text_blocks):
        print(f"ğŸ§© ë¸”ë¡ {idx+1} ìš”ì•½ ì¤‘...")
        summary = await summarize_with_assistant(block)
        partial_summaries.append(summary)

    # 5. ë¶€ë¶„ ìš”ì•½ í•©ì¹˜ê¸°
    combined_summary_text = "\n\n".join(partial_summaries)

    # 6. ìµœì¢… ìš”ì•½
    print("ğŸ§  ìµœì¢… ìš”ì•½ ì‹œì‘...")
    final_summary = await summarize_with_assistant(combined_summary_text)

    # âœ… ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œ
    del lecture_texts[lecture_id]

    return {
        "lecture_id": lecture_id,
        "summary": final_summary
    }

# ğŸ”¥ Assistantë¡œ í…ìŠ¤íŠ¸ í´ë¦°ì—…í•˜ëŠ” í•¨ìˆ˜
async def ai_clean_text(text: str) -> str:
    thread = await openai_client.beta.threads.create()

    await openai_client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=f"""
ì•„ë˜ ìˆ˜ì—… ë…¹ì·¨ë¡ì—ì„œ ë‹¤ìŒì— í•´ë‹¹í•˜ëŠ” ë¬¸ì¥ì„ ëª¨ë‘ ì œê±°í•´ ì£¼ì„¸ìš”:
- ì˜ë¯¸ ì—†ëŠ” ì¡ë‹´ (ì˜ˆ: ìŒ, ì–´, ëŠê¸°ëŠ” ë§, unrelated small talk)
- ê°•ì˜ ì£¼ì œì™€ ë¬´ê´€í•œ ëŒ€í™”
- ì–´ìƒ‰í•˜ê±°ë‚˜ ì—°ê²°ì´ ì•ˆ ë˜ëŠ” ì¤‘ê°„ ë©˜íŠ¸

ì˜¤ë¡œì§€ ê°•ì˜ í•µì‹¬ ë‚´ìš©, ìˆ˜ì—… ì„¤ëª…ë§Œ ë‚¨ê¸°ê³  ì •ë¦¬í•´ ì£¼ì„¸ìš”.

ìˆ˜ì—… í…ìŠ¤íŠ¸:
{text}
        """
    )

    run = await openai_client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=ASSISTANT_ID
    )

    while True:
        run_status = await openai_client.beta.threads.runs.retrieve(
            thread_id=thread.id,
            run_id=run.id
        )
        if run_status.status in ["completed", "failed", "cancelled", "expired"]:
            break
        await asyncio.sleep(1)

    if run_status.status != "completed":
        raise Exception(f"AI í´ë¦°ì—… ì‹¤íŒ¨: {run_status.status}")

    messages = await openai_client.beta.threads.messages.list(thread_id=thread.id)
    cleaned_text = messages.data[0].content[0].text.value.strip()

    return cleaned_text

# ğŸ”¥ Assistantë¡œ í…ìŠ¤íŠ¸ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜
async def summarize_with_assistant(text: str) -> str:
    thread = await openai_client.beta.threads.create()

    await openai_client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=f"""
ë‹¤ìŒì€ ìˆ˜ì—… ë…¹ì·¨ë¡ ì¼ë¶€ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë¶€ë“œëŸ½ê³  ê¹”ë”í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.

ìˆ˜ì—… í…ìŠ¤íŠ¸:
{text}
        """
    )

    run = await openai_client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=ASSISTANT_ID
    )

    while True:
        run_status = await openai_client.beta.threads.runs.retrieve(
            thread_id=thread.id,
            run_id=run.id
        )
        if run_status.status in ["completed", "failed", "cancelled", "expired"]:
            break
        await asyncio.sleep(1)

    if run_status.status != "completed":
        raise Exception(f"Run ì‹¤íŒ¨: {run_status.status}")

    messages = await openai_client.beta.threads.messages.list(thread_id=thread.id)
    summary_text = messages.data[0].content[0].text.value.strip()

    return summary_text
