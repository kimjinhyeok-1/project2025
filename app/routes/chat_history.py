from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from app.database import get_db
from app.auth import get_current_user_id, verify_student, verify_professor  # âœ… ì¶”ê°€ë¨
from app.models import QuestionAnswer
import openai
import os

router = APIRouter()

# âœ… í•™ìƒ ìì‹ ì˜ ì§ˆë¬¸ ë‚´ì—­ í™•ì¸ (í•™ìƒ ì „ìš©)
@router.get("/chat_history/me")
async def get_my_chat_history(
    db: AsyncSession = Depends(get_db),
    user_id: int = Depends(get_current_user_id),
    _: str = Depends(verify_student)  # âœ… í•™ìƒë§Œ ì ‘ê·¼ ê°€ëŠ¥
):
    result = await db.execute(
        select(QuestionAnswer)
        .where(QuestionAnswer.user_id == user_id)
        .order_by(QuestionAnswer.created_at.desc())
    )
    records = result.scalars().all()
    return [
        {
            "question": r.question,
            "answer": r.answer,
            "created_at": r.created_at.isoformat()
        }
        for r in records
    ]

# âœ… ì „ì²´ ì§ˆë¬¸ ë‚´ì—­ í™•ì¸ (êµìˆ˜ì ì „ìš©, ì§ˆë¬¸ì ì •ë³´ ì—†ìŒ)
@router.get("/chat_history/all")
async def get_all_chat_history(
    db: AsyncSession = Depends(get_db),
    #_: str = Depends(verify_professor)
):
    result = await db.execute(
        select(QuestionAnswer).order_by(QuestionAnswer.created_at.desc())
    )
    records = result.scalars().all()
    print("ğŸ“¦ records ê°œìˆ˜:", len(records))  # ğŸ” ì´ê±° ì¶”ê°€
    return [
        {
            "question": r.question,
            "answer": r.answer,
            "created_at": r.created_at.isoformat()
        }
        for r in records
    ]

# âœ… ì§ˆë¬¸ ìš”ì•½ ê¸°ëŠ¥ (êµìˆ˜ì ì „ìš©)
@router.get("/chat_history/summary")
async def get_question_summary(
    db: AsyncSession = Depends(get_db),
    _: str = Depends(verify_professor)
):
    try:
        result = await db.execute(select(QuestionAnswer.question))
        questions = [row[0] for row in result.all()]

        if not questions:
            return {"message": "ì§ˆë¬¸ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}

        prompt = f"""
        ë‹¤ìŒì€ í•™ìƒë“¤ì´ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤:
        {questions}

        êµìˆ˜ë‹˜ì„ ìœ„í•œ ìš”ì•½ì„ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”. í•™ìƒë“¤ì´ ì–´ë ¤ì›Œí•˜ëŠ” ê°œë…ì„ ì„¤ëª…í•˜ê³ , ë³´ì¶©í•  ë‚´ìš©ì„ ì¶”ì²œí•˜ì„¸ìš”.
        """

        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300,
            temperature=0.7,
        )
        summary = response.choices[0].message.content.strip()

        return {
            "most_common_questions": questions[:5],
            "summary_for_professor": summary
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
