import os
from openai import AsyncOpenAI
from app.models import Snapshot

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ASSISTANT_ID = os.getenv("OPENAI_SUMMARY_ASSISTANT_ID")
BASE_URL = os.getenv("BASE_URL", "")

client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# ğŸ“Œ GPT ê¸°ë°˜ ë§ˆí¬ë‹¤ìš´ ìš”ì•½ (Assistant API ë²„ì „)
async def summarize_text_with_gpt(text: str) -> str:
    thread = await client.beta.threads.create()
    await client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=text
    )
    run = await client.beta.threads.runs.create_and_poll(
        thread_id=thread.id,
        assistant_id=ASSISTANT_ID
    )
    messages = await client.beta.threads.messages.list(thread_id=thread.id)
    return messages.data[0].content[0].text.value.strip()

# âœ… ê°œì„ ëœ ìŠ¤ëƒ…ìƒ· STT ìš”ì•½ í•¨ìˆ˜ (í•œ ë¬¸ì¥ ìš”ì•½)
async def summarize_snapshot_transcript(transcript: str) -> str:
    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ Java ìˆ˜ì—… ì¤‘ êµìˆ˜ë‹˜ì˜ ì„¤ëª…ì„ ìš”ì•½í•˜ëŠ” ì „ë¬¸ ë¹„ì„œì…ë‹ˆë‹¤.\n\n"
                    "ğŸ“Œ ë‹¤ìŒ ì›ì¹™ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:\n"
                    "1. **í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½**í•˜ë©°, **ì¤‘ìš” ê°œë…ì´ë‚˜ ë¹„êµ ì„¤ëª…ì„ ë°˜ë“œì‹œ ë°˜ì˜**í•˜ì„¸ìš”.\n"
                    "2. '~ì— ëŒ€í•´ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤'ì™€ ê°™ì€ ì¼ë°˜ì  ë¬¸ì¥ì€ í”¼í•˜ê³ , **êµìˆ˜ë‹˜ì˜ ê°•ì¡°ì ì´ë‚˜ ì„¤ëª… ë°©ì‹ì„ ë“œëŸ¬ë‚´ì„¸ìš”.**\n"
                    "3. ì„¤ëª… ë‚´ìš©ì´ ë‹¨ìˆœí•˜ë”ë¼ë„ ì„ì˜ë¡œ ë³´ì™„í•˜ì§€ ë§ê³ , **ì£¼ì–´ì§„ ë‚´ìš© ì•ˆì—ì„œ ê°€ì¥ í•µì‹¬ë§Œ ì••ì¶•**í•˜ì„¸ìš”.\n\n"
                    "âœï¸ ì˜ˆì‹œ:\n"
                    "- 'í´ë˜ìŠ¤ì™€ ê°ì²´ì˜ ê°œë…ì„ êµ¬ë¶„í•˜ë©°, ê°ì²´ëŠ” í´ë˜ìŠ¤ì—ì„œ ìƒì„±ë˜ëŠ” ì‹¤ì²´ì„ì„ ê°•ì¡°í•˜ì…¨ìŠµë‹ˆë‹¤.'\n"
                    "- 'ê°’ ì „ë‹¬ê³¼ ì°¸ì¡° ì „ë‹¬ì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•˜ë©°, ë©”ëª¨ë¦¬ ê´€ì ì—ì„œì˜ ë™ì‘ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ì…¨ìŠµë‹ˆë‹¤.'"
                )
            },
            {"role": "user", "content": transcript}
        ],
        max_tokens=150,
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()

# âœ… ì£¼ì œë³„ ê´€ë ¨ì„± ë†’ì€ ìŠ¤ëƒ…ìƒ· 1~2ê°œ ì„ íƒ (is_image=True í•„í„°ë§ì€ ìƒìœ„ì—ì„œ ìˆ˜í–‰)
async def pick_top2_snapshots_by_topic(topic: str, snapshots: list[Snapshot], max_count: int = 2, used_paths: set[str] = set()) -> list[int]:
    valid_snapshots = []
    snapshot_map = []
    for i, snap in enumerate(snapshots):
        if not snap.image_path or snap.image_path in used_paths:
            continue
        valid_snapshots.append(snap)
        snapshot_map.append(i)

    if not valid_snapshots:
        return []

    prompt = (
        f"ë‹¤ìŒì€ ê°•ì˜ ì£¼ì œì…ë‹ˆë‹¤:\n\n'{topic}'\n\n"
        f"ì•„ë˜ëŠ” êµìˆ˜ë‹˜ì˜ ì„¤ëª… ìš”ì•½ì…ë‹ˆë‹¤:\n\n" +
        "\n".join([f"{i+1}. {snap.text}" for i, snap in enumerate(valid_snapshots)]) +
        f"\n\nìœ„ ì£¼ì œì™€ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì„¤ëª…ì„ 1ê°œ ~ 2ê°œ ì„ íƒí•˜ì„¸ìš”. "
        f"ì¤‘ë³µë˜ëŠ” ê²½ìš°ëŠ” 1ê°œë§Œ ì„ íƒí•˜ê³ , ë²ˆí˜¸ë§Œ ì½¤ë§ˆ ì—†ì´ í•œ ì¤„ì— ì¶œë ¥í•˜ì„¸ìš” (ì˜ˆ: 1 ë˜ëŠ” 1,2)"
    )

    res = await client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        max_tokens=20,
    )
    text = res.choices[0].message.content.strip()
    try:
        indices = [int(x.strip()) - 1 for x in text.split(",") if x.strip().isdigit()]
        unique_indices = list(dict.fromkeys([i for i in indices if 0 <= i < len(valid_snapshots)]))
        result = [snapshot_map[i] for i in unique_indices[:max_count]]
        for i in result:
            used_paths.add(snapshots[i].image_path)
        return result
    except Exception:
        return []