import os
import subprocess
import torch
import torchaudio
from typing import List, Tuple
import whisper
from silero_vad import VoiceActivityDetector, collect_chunks


# âœ… 1. webm â†’ wav ë³€í™˜
def convert_webm_to_wav(webm_path: str) -> str:
    wav_path = webm_path.replace(".webm", ".wav")
    command = f"ffmpeg -y -i {webm_path} -ar 16000 -ac 1 {wav_path}"
    subprocess.run(command, shell=True)
    return wav_path


# âœ… 2. Sileroë¡œ ë§í•œ êµ¬ê°„ íƒì§€ â†’ [start, end] (ì´ˆ ë‹¨ìœ„)
def get_speech_timestamps(wav_path: str) -> List[Tuple[float, float]]:
    # ì˜¤ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°
    wav, sample_rate = torchaudio.load(wav_path)
    if sample_rate != 16000:
        wav = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(wav)

    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = VoiceActivityDetector()
    speech_chunks = model.detect_voice(wav[0], sample_rate=16000)

    return speech_chunks


# âœ… 3. Whisperë¡œ ë§í•œ êµ¬ê°„ë“¤ë§Œ STT
def transcribe_with_whisper(wav_path: str) -> str:
    print("ğŸ“¦ Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = whisper.load_model("base")

    print("ğŸ” ë§í•œ êµ¬ê°„ ì¶”ì¶œ ì¤‘ (Silero)...")
    speech_timestamps = get_speech_timestamps(wav_path)

    if not speech_timestamps:
        return "âš ï¸ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    # ì „ì²´ ì˜¤ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°
    wav, _ = torchaudio.load(wav_path)

    results = []
    for idx, (start_sec, end_sec) in enumerate(speech_timestamps):
        start_sample = int(start_sec * 16000)
        end_sample = int(end_sec * 16000)

        chunk_path = wav_path.replace(".wav", f"_chunk{idx}.wav")
        torchaudio.save(chunk_path, wav[:, start_sample:end_sample], 16000)

        result = model.transcribe(chunk_path, language="ko")
        results.append(result["text"])

    return "\n".join(results)
